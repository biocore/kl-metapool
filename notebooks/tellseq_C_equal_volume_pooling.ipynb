{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%reload_ext watermark\n",
    "%matplotlib inline\n",
    "\n",
    "from contextlib import suppress\n",
    "from datetime import datetime\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from metapool.metapool import *\n",
    "from metapool import (make_sample_sheet, find_threshold, autopool)\n",
    "from metapool.mp_strings import (PM_LIB_WELL_KEY, PM_COMPRESSED_PLATE_NAME_KEY,\n",
    "    MINIPICO_LIB_CONC_KEY, TELLSEQ_BARCODE_SET_ID_KEY, TELLSEQ_BARCODE_ID_KEY)\n",
    "from metapool.sample_sheet import (\n",
    "    TELLSEQ_METAG_SHEET_TYPE, TELLSEQ_ABSQUANT_SHEET_TYPE, make_sections_dict)\n",
    "from metapool.util import get_set_fp, warn_if_fp_exists\n",
    "%watermark -i -v -iv -m -h -p metapool,sample_sheet,openpyxl -u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knight Lab TellSeq pipeline notebook C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 (of 5): Workflow for normalizing DNA\n",
    "\n",
    "This portion of the notebook will construct an Echo normalization picklist file for the selected barcode set.\n",
    "\n",
    "As inputs, it requires:\n",
    "1. A tab-delimited `*_plate_df_A.txt` file containing the quantitations for the entire 384-well plate\n",
    "2. A yaml file containing the experiment name and info on the included studies\n",
    "\n",
    "The workflow then:\n",
    "1. reads in the specified input files\n",
    "2. calculates the pooling volumes for the samples in the selected barcode set\n",
    "3. produces an Echo-formatted pick list file for that set\n",
    "4. produces a tab-delimited `*_plate_df_C_set_*.txt` file containing the plate df for (only) the samples in this barcode set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 of 7: Read in the 384-well plate data and the experiment info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUT\n",
    "full_plate_fp = './test_output/QC/Tellseq_absquant_plate_df_B.txt'\n",
    "expt_config_fp = './test_output/QC/Tellseq_expt_info.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the full_plate_fp does not end with \"plate_df_B.txt\", throw an error\n",
    "expected_suffix = f\"plate_df_B.txt\"\n",
    "if not full_plate_fp.endswith(expected_suffix):\n",
    "    raise ValueError(f\"Expected file ending with '{expected_suffix}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_fp in [full_plate_fp, expt_config_fp]:\n",
    "    if not os.path.isfile(curr_fp):\n",
    "        print(\"Problem! %s is not a path to a valid file\" % curr_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_plate_df = pd.read_csv(full_plate_fp, sep='\\t')\n",
    "full_plate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_absquant(full_plate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(expt_config_fp, 'r') as f:\n",
    "    expt_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = expt_config['experiment_name']\n",
    "expt_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_studies_info = expt_config['studies']\n",
    "full_studies_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ids = full_plate_df[TELLSEQ_BARCODE_SET_ID_KEY].unique()\n",
    "set_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 of 7: Select the barcode set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the barcode set to process in this notebook and set it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUT\n",
    "current_set_id = \"col19to24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df = full_plate_df[full_plate_df[TELLSEQ_BARCODE_SET_ID_KEY] == current_set_id].copy()\n",
    "plate_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that there are no duplicate barcodes in the selected plate df.  This must return True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DECISION -- verify no duplicate barcodes\n",
    "plate_df[TELLSEQ_BARCODE_ID_KEY].value_counts().nunique() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_col_key = f\"{PM_LIB_WELL_KEY}_row\"\n",
    "col_col_key = f\"{PM_LIB_WELL_KEY}_col\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_well_names = make_compressed_2d_array(\n",
    "    plate_df, data_col=PM_LIB_WELL_KEY, \n",
    "    row_col=row_col_key, col_col=col_col_key)\n",
    "source_well_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_projects = plate_df[PM_PROJECT_NAME_KEY].unique()\n",
    "studies_info = []\n",
    "for a_study in full_studies_info:\n",
    "    if a_study[PM_PROJECT_NAME_KEY] in unique_projects:\n",
    "        studies_info.append(a_study)\n",
    "studies_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 of 7: Calculate pooling values for MiniPico with autopool\n",
    "\n",
    "This step will calculate the sample pooling, and update the sample data frame with the pool info.\n",
    "There are two automated methods to pool:\n",
    "1. **norm**: This will attempt to generate a normalized pool, automatically inferring the best parameter for pooling.\n",
    "    - ***pool_failures***:\n",
    "        - _high_: will pool failures at the highest pooling volume from optimized pooling.\n",
    "        - _low_: will pool failures at the lowest pooling volume from optimized pooling.\n",
    "\n",
    "2. **evp**: This will pool an even volume per sample.\n",
    "    - ***total_vol***: (Optional, Default: 100ÂµL) The total volume to pool, in uL. Each sample will be pooled at 1/N of that volume, where N is total number of samples in the prep.\n",
    "\n",
    "3. **automate**: (Optional, Default = True) When False, this argument will allow one input parameters for **Legacy** arguments. \n",
    "\n",
    "> **Legacy**\n",
    "> There are legacy parameters to control pooling behaviors when autopool automation (automate=True) returns a poor result. To use these parameters, one must pass automate=False.\n",
    "\n",
    ">   - **min_conc**: (default: 0) This is the minimum concentration for a sample to be considered for pooling.\n",
    "    Set to 0 to pool all samples, regardless of concentration. Increasing this will have the \n",
    "    effect of increasing pool concentration, at the expense of samples dropping out. \n",
    ">   - **floor_conc**: This is the lowest concentration equivalent for which a sample will be \n",
    "    accurately pooled. Samples below this concentration will be pooled to the volume that they \n",
    "    would have been if they were actually that concentration. For example, if `floor_conc=20`, \n",
    "    and a sample at 20 nM pools at 500 nL, a sample at 40 nM will pool at 250 nL but a sample at \n",
    "    10 nM will still pool at 500 nL (rather than 1000). Increasing this value will have the effect \n",
    "    of increasing pool concentration, but decreasing read counts for low-concentration samples. \n",
    ">   - **total_nmol**: This is the total number of molecules to shoot for in the pool. Increasing\n",
    "    this will increase the overall volume of the pool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUT -- verify default\n",
    "total_vol = 190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df = autopool(plate_df,method='evp',total_vol=total_vol)\n",
    "plate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINIPICO_POOLED_VOL_KEY = 'MiniPico Pooled Volume'\n",
    "\n",
    "vols = make_compressed_2d_array(\n",
    "    plate_df, data_col=MINIPICO_POOLED_VOL_KEY, \n",
    "    row_col=row_col_key, col_col=col_col_key\n",
    ").astype(float)\n",
    "vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold = find_threshold(plate_df[MINIPICO_LIB_CONC_KEY], plate_df[PM_BLANK_KEY])\n",
    "threshold = find_threshold(plate_df['MiniPico Library Concentration'], plate_df['Blank'])\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "print(\"Floor concentration: {}\".format(threshold))\n",
    "conc, vol = estimate_pool_conc_vol(plate_df[MINIPICO_POOLED_VOL_KEY], plate_df[MINIPICO_LIB_CONC_KEY])\n",
    "print(\"Pool concentration: {:.2f}\".format(conc))\n",
    "print(\"Pool volume: {:.2f}\".format(vol))\n",
    "with suppress(np.linalg.LinAlgError):\n",
    "    plot_plate_vals(vols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=MINIPICO_LIB_CONC_KEY, y=MINIPICO_POOLED_VOL_KEY,data=plate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 of 7: Make equal volume pooling pick list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUT\n",
    "evp_picklist_fbase = './test_output/Indices/Tellseq_evp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evp_picklist = format_pooling_echo_pick_list(\n",
    "    vols, max_vol_per_well=30000, source_well_names=source_well_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evp_picklist_fp = get_set_fp(evp_picklist_fbase, current_set_id)\n",
    "evp_picklist_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warn_if_fp_exists(evp_picklist_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(evp_picklist_fp,'w') as f:\n",
    "    f.write(evp_picklist)\n",
    "\n",
    "!head {evp_picklist_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 of 7: Make machine samplesheet for iSeq instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUT\n",
    "machine_samplesheet_fbase = './test_output/SampleSheets/Tellseq_absquant_samplesheet_instrument_iseq'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not change the below constants unless you really know what you are doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_SHEET_TEMPLATE = \"\"\"[Header],,,,,,,,,,,\n",
    "Experiment Name,{expt_name},,,,,,,,,,\n",
    "Investigator Name,Enter the investigator name (optional),,,,,,,,,,\n",
    "Project Name,{proj_name},,,,,,,,,,\n",
    "Date,{today_date},,,,,,,,,,\n",
    "Workflow,GenerateFASTQ,,,,,,,,,,\n",
    "Library Prep Kit,TELLSEQ,,,,,,,,,,\n",
    "[Manifest],,,,,,,,,,,\n",
    "Enter the manifest files used to align to targeted reference regions of the genome. Use the following format.,,,,,,,,,,,\n",
    "ManifestKey, ManifestFile,,,,,,,,,,\n",
    "[Reads],,,,,,,,,,,\n",
    "146,,,,,,,,,,,\n",
    "146,,,,,,,,,,,\n",
    "[Settings],,,,,,,,,,,\n",
    "Enter any analysis settings. See the example setting below,,,,,,,,,,,\n",
    "Adapter, CTGTCTCTTATACACATCT,,,,,,,,,,\n",
    "[Data],,,,,,,,,,,\n",
    "Enter sample information for the run in this section,,,,,,,,,,,\n",
    "Sample_ID,Sample_Name,Sample_Plate,Description,I7_Index_ID,index,I5_Index_ID,index2,Manifest,GenomeFolder,Sample_Project,Sample_Well\n",
    "Sample1,,A,A1,7027,NNNNNNNNNNNNNNNNNN,5001,NNNNNNNNNN,,,,\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_set_machine_sheet_str(a_plate_df, an_expt_name, a_set_id):\n",
    "    set_expt_name = f\"{an_expt_name}_{a_set_id}\"\n",
    "    # TODO: this is a bit of a hack; you can end up with multiple \n",
    "    #  compressed plate names due to multiple dilutions, and there's no \n",
    "    #  guarantee that every 96-sample barcode set will happen to pull from all\n",
    "    #  the same dilution plates as all the others.  But I think it will still\n",
    "    #  be clear to a human that they all come from the same project.\n",
    "    compressed_plate_name = \\\n",
    "        sorted(list(a_plate_df[PM_COMPRESSED_PLATE_NAME_KEY].unique()))[0]\n",
    "    curr_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    result = MACHINE_SHEET_TEMPLATE.format(\n",
    "        expt_name=set_expt_name, proj_name=compressed_plate_name, \n",
    "        today_date=curr_date)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_sheet_str = make_set_machine_sheet_str(\n",
    "    plate_df, expt_name, current_set_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_samplesheet_fp = get_set_fp(\n",
    "    machine_samplesheet_fbase, current_set_id, extension=\"csv\")\n",
    "warn_if_fp_exists(machine_samplesheet_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(machine_samplesheet_fp,'w') as f:\n",
    "    f.write(machine_sheet_str)\n",
    "    \n",
    "!head {machine_samplesheet_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 of 7: Make iSeq and NovaSeqX samplesheets for the SPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUT\n",
    "spp_samplesheet_fbase = './test_output/SampleSheets/Tellseq_absquant_samplesheet_spp'\n",
    "iseq_sequencer = 'iSeq'\n",
    "novaseq_sequencer = 'NovaSeqXPlus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanes = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS: Users, DO NOT CHANGE THESE\n",
    "# values without consulting with tech team\n",
    "SHEET_TYPE_VERSIONS = {\n",
    "    TELLSEQ_METAG_SHEET_TYPE: '10',  # version supporting SampleContext\n",
    "    TELLSEQ_ABSQUANT_SHEET_TYPE: '10'\n",
    "}\n",
    "\n",
    "BIOINFO_BASE = {\n",
    "    'ForwardAdapter': 'GATCGGAAGAGCACACGTCTGAACTCCAGTCAC',\n",
    "    'ReverseAdapter': 'GATCGGAAGAGCGTCGTGTAGGGAAAGGAGTGT',\n",
    "    'library_construction_protocol': 'Knight Lab Kapa HyperPlus',\n",
    "    # The BarcodesAreRC value is no longer used, but is still checked for\n",
    "    # by the validation while making the sample sheet, so put in a dummy value\n",
    "    'BarcodesAreRC': 'True'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the sample sheet type to make\n",
    "expt_type = TELLSEQ_ABSQUANT_SHEET_TYPE if is_absquant(plate_df) \\\n",
    "    else TELLSEQ_METAG_SHEET_TYPE\n",
    "expt_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the metadata dictionary with additional information\n",
    "metadata_dict_w_sample_context = make_sections_dict(\n",
    "    plate_df, studies_info, expt_name,\n",
    "    expt_type, SHEET_TYPE_VERSIONS[expt_type], BIOINFO_BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iseq_spp_sheet = make_sample_sheet(\n",
    "    metadata_dict_w_sample_context, plate_df, iseq_sequencer, lanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iseq_spp_samplesheet_fp = get_set_fp(\n",
    "    f\"{spp_samplesheet_fbase}_{iseq_sequencer.lower()}\", current_set_id, \n",
    "    extension=\"csv\")\n",
    "warn_if_fp_exists(iseq_spp_samplesheet_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(iseq_spp_samplesheet_fp,'w') as f:\n",
    "    iseq_spp_sheet.write(f)\n",
    "\n",
    "!head {iseq_spp_samplesheet_fp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novaseq_spp_sheet = make_sample_sheet(\n",
    "    metadata_dict_w_sample_context, plate_df, novaseq_sequencer, lanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novaseq_spp_samplesheet_fp = get_set_fp(\n",
    "    f\"{spp_samplesheet_fbase}_{novaseq_sequencer.lower()}\", current_set_id, \n",
    "    extension=\"csv\")\n",
    "warn_if_fp_exists(novaseq_spp_samplesheet_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(novaseq_spp_samplesheet_fp,'w') as f:\n",
    "    novaseq_spp_sheet.write(f)\n",
    "\n",
    "!head {novaseq_spp_samplesheet_fp}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 of 7: Write plate set dataframe to file\n",
    "\n",
    "Save the plate dataframe for this set containing the pooled volume results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_set_fbase = full_plate_fp.replace(\"B.txt\", f\"C\")\n",
    "plate_set_fp = get_set_fp(plate_set_fbase, current_set_id)\n",
    "plate_set_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warn_if_fp_exists(plate_set_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_df.to_csv(plate_set_fp, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "473px",
    "width": "381px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "740px",
    "left": "0px",
    "right": "1407.6666259765625px",
    "top": "112px",
    "width": "211.705px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
