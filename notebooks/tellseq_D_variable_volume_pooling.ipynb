{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%reload_ext watermark\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re \n",
    "from contextlib import suppress\n",
    "from metapool.metapool import *\n",
    "from metapool.util import (join_dfs_from_files, get_set_fp, warn_if_fp_exists, \n",
    "                           SET_SUFFIX)\n",
    "from metapool.mp_strings import (\n",
    "    PM_BLANK_KEY, MINIPICO_LIB_CONC_KEY, PM_LIB_WELL_KEY, \n",
    "    TELLSEQ_BARCODE_ID_KEY)\n",
    "%watermark -i -v -iv -m -h -p metapool,sample_sheet,openpyxl -u"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "! conda list",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Knight Lab TellSeq pipeline notebook D "
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 (of 5): Workflow for Read Distribution Summary and Pool Normalization\n",
    "\n",
    "### Step 1 of 5: Import plate info for this barcode set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## INPUT\n",
    "plate_df_set_fp = './test_output/QC/Tellseq__plate_df_C_set_col19to24.txt'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# if the plate_df_set_fp does not end with \"C_set_*.txt\", throw an error\n",
    "expected_suffix = rf\"C{SET_SUFFIX}_.+\\.txt$\"\n",
    "\n",
    "# Check if the file path matches the pattern\n",
    "if not re.search(expected_suffix, plate_df_set_fp):\n",
    "    raise ValueError(f\"Expected file ending with '{expected_suffix}'\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if not os.path.isfile(plate_df_set_fp):\n",
    "    print(\"Problem! %s is not a path to a valid file\" % plate_df_set_fp)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plate_df = pd.read_csv(plate_df_set_fp, sep='\\t')\n",
    "plate_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that there are no duplicate barcodes in the selected plate df. This must return True."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## DECISION -- verify no duplicate barcodes\n",
    "plate_df[TELLSEQ_BARCODE_ID_KEY].value_counts().nunique() == 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# split the evp_plate_df_set_fp to extract the set id\n",
    "_, set_str = os.path.splitext(plate_df_set_fp)[0].rsplit(SET_SUFFIX, 1)\n",
    "current_set_id = set_str.replace(\"_\", \"\").replace(\".txt\", \"\")\n",
    "current_set_id"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "row_col_key = f\"{PM_LIB_WELL_KEY}_row\"\n",
    "col_col_key = f\"{PM_LIB_WELL_KEY}_col\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "source_well_names = make_compressed_2d_array(\n",
    "    plate_df, data_col=PM_LIB_WELL_KEY, \n",
    "    row_col=row_col_key, col_col=col_col_key)\n",
    "source_well_names"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 of 5: Import and merge per_sample read distributions for this set\n",
    "\n",
    "Import tsv file(s) with read_counts from per_sample_fastq files and merge with growing plate_df\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## INPUT\n",
    "# Make sure this is for the same barcode set as the plate df file.\n",
    "# Enter paths to read counts file(s)\n",
    "read_counts_fps = [\n",
    "    './test_data/Demux/Tellseq_fastqc_sequence_counts.tsv',\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import reads counts from file to dataframes\n",
    "CATEGORY_KEY = 'Category'\n",
    "UNIQUE_READS_KEY = 'Unique Reads'\n",
    "DUPLICATE_READS_KEY = 'Duplicate Reads'\n",
    "read_counts_df = join_dfs_from_files(\n",
    "    read_counts_fps, [CATEGORY_KEY, UNIQUE_READS_KEY, DUPLICATE_READS_KEY],\n",
    "    unique_cols=[CATEGORY_KEY], \n",
    "    dtype={CATEGORY_KEY: str, UNIQUE_READS_KEY: int, DUPLICATE_READS_KEY: int})\n",
    "    \n",
    "trimmed_reads_mask = read_counts_df[CATEGORY_KEY].str.contains('trimmed')\n",
    "raw_read_counts_df = read_counts_df.loc[~trimmed_reads_mask].copy()\n",
    "filtered_read_counts_df = read_counts_df.loc[trimmed_reads_mask].copy()\n",
    "\n",
    "##Can also import counts from Qiita per_sample_FASTQ summaries.  \n",
    "# per_sample_fastq_counts_df = pd.read_csv('./test_data/Demux/YYYY_MM_DD_Celeste_Adaptation_16_17_18_21_per_sample_fastq.tsv',\n",
    "#                                          sep='\\t')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Merge read_counts_df with plate_df \n",
    "plate_df_w_reads = merge_read_counts(\n",
    "    plate_df, raw_read_counts_df, \n",
    "    reads_column_name='Raw Reads')\n",
    "plate_df_w_reads = merge_read_counts(\n",
    "    plate_df_w_reads, filtered_read_counts_df, \n",
    "    reads_column_name='Filtered Reads')\n",
    "\n",
    "# plate_df_w_reads = merge_read_counts(\n",
    "#    plate_df_w_reads, per_sample_fastq_counts_fp,\n",
    "#    reads_column_name='Qiita Reads')\n",
    "\n",
    "plate_df_w_reads.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "reads_column = 'Raw Reads'\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))\n",
    "# evenness plot\n",
    "rmax = int(round(plate_df_w_reads[reads_column].max(),-2))\n",
    "survival_df = pd.concat([read_survival(plate_df_w_reads.loc[plate_df_w_reads[PM_BLANK_KEY] == True,\n",
    "                                                            reads_column], label='Blanks',rmax=rmax),\n",
    "                         read_survival(plate_df_w_reads.loc[plate_df_w_reads[PM_BLANK_KEY] == False,\n",
    "                                                            reads_column], label='Samples',rmax=rmax)])\n",
    "\n",
    "ax3.set_xlabel(reads_column)\n",
    "ax3.set_ylabel('Samples')\n",
    "survival_df.plot(color = ['coral','steelblue'],ax=ax1)\n",
    "ax1.set_xlabel(reads_column)\n",
    "ax1.set_ylabel('Samples')\n",
    "\n",
    "##Histogram\n",
    "sns.histplot(plate_df_w_reads[reads_column],ax=ax3)\n",
    "\n",
    "##Regressopm\n",
    "sns.regplot(x=\"MiniPico Library DNA Concentration\", y=reads_column, data=plate_df_w_reads, ax = ax2)\n",
    "\n",
    "#Boxplot\n",
    "sns.boxplot(x=PM_BLANK_KEY, y=reads_column, data=plate_df_w_reads, ax = ax4)\n",
    "sns.stripplot(x=PM_BLANK_KEY, y=reads_column, data=plate_df_w_reads, ax = ax4,\n",
    "              size=3,color='black',alpha=0.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 of 5: Calculate iSeqnorm pooling volumes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## INPUT\n",
    "dynamic_range = 5"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plate_df_normalized = calculate_iseqnorm_pooling_volumes(\n",
    "    plate_df_w_reads,dynamic_range=dynamic_range, normalization_column='Raw Reads')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ISEQ_NORM_VOL_KEY = 'iSeq normpool volume'\n",
    "\n",
    "vols = make_compressed_2d_array(\n",
    "    plate_df_normalized, data_col=ISEQ_NORM_VOL_KEY, \n",
    "    row_col=row_col_key, col_col=col_col_key).astype(float)\n",
    "vols"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# visualize\n",
    "conc, vol = estimate_pool_conc_vol(\n",
    "    plate_df_normalized[ISEQ_NORM_VOL_KEY], \n",
    "    plate_df_normalized[MINIPICO_LIB_CONC_KEY])\n",
    "print(\"Pool concentration: {:.2f}\".format(conc))\n",
    "print(\"Pool volume: {:.2f}\".format(vol))\n",
    "with suppress(np.linalg.LinAlgError):\n",
    "    plot_plate_vals(vols)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 of 5: Estimate read depth"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Plots estimate of read depth proportion, and returns a df with estimates. \n",
    "plate_df_normalized_with_estimates = estimate_read_depth(plate_df_normalized)\n",
    "plate_df_normalized_with_estimates.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 of 5: Make pooling picklist and write to a file"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "## INPUT\n",
    "iseqnormed_picklist_fbase = './test_output/Pooling/Tellseq_iSeqnormpool'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "iseqnormed_picklist = format_pooling_echo_pick_list(\n",
    "    vols, max_vol_per_well=30000, source_well_names=source_well_names)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "iseqnormed_picklist_fp = get_set_fp(iseqnormed_picklist_fbase, current_set_id)\n",
    "warn_if_fp_exists(iseqnormed_picklist_fp)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with open(iseqnormed_picklist_fp,'w') as fh:\n",
    "    fh.write(iseqnormed_picklist)\n",
    "\n",
    "!head {iseqnormed_picklist_fp}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "473px",
    "width": "381px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "740px",
    "left": "0px",
    "right": "1407.6666259765625px",
    "top": "112px",
    "width": "211.705px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
